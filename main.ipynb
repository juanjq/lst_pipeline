{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95048a67",
   "metadata": {},
   "source": [
    "## Import needed packaes and scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "import pickle, json, sys, os, glob\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import utils\n",
    "\n",
    "# Lstchain packages\n",
    "from traitlets.config.loader import Config\n",
    "from astropy.coordinates     import SkyCoord\n",
    "from lstchain.io.config      import get_standard_config\n",
    "from ctapipe.io              import read_table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff6f04",
   "metadata": {},
   "source": [
    "# Some configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ff173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source specifications\n",
    "source_name = \"crab\"\n",
    "\n",
    "# Maybe we add a way to extract the run numbers we are interested in\n",
    "run_numbers = [10880] # [6172, 6242, 6194, 6193, 15337, 15272, 15339, 15340] # [15272] # [15337, 15272]\n",
    "# The number of subruns we want to analyse, None = all\n",
    "subruns_num = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea7368",
   "metadata": {},
   "source": [
    "# Paths to data and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66854bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root path of this script\n",
    "root = \"/fefs/aswg/workspace/juan.jimenez/lst_pipeline/\"\n",
    "# Path to store the configuration file we are going to use\n",
    "config_file = root + \"objects/standard_config.json\"\n",
    "# Data main directory\n",
    "root_data = root + f\"../data/tests/{source_name}/\"\n",
    "\n",
    "# STANDARD paths ---------\n",
    "# DL1 data root\n",
    "dl1_root = \"/fefs/aswg/data/real/DL1/*/v0.*/tailcut84/\"\n",
    "# RFs root main directory\n",
    "rfs_root = \"/fefs/aswg/data/models/AllSky/20230901_v0.10.4_allsky_base_prod/\"\n",
    "# MCs dl2 main directory\n",
    "mcs_root = \"/fefs/aswg/data/mc/DL2/AllSky/20230901_v0.10.4_allsky_base_prod/TestingDataset/\"\n",
    "\n",
    "\n",
    "# directories for the data\n",
    "dir_dl1b = root_data + \"dl1b/\"\n",
    "dir_dl2  = root_data + \"dl2/\"\n",
    "dir_dl2m = root_data + \"dl2_merged/\"\n",
    "dir_dl3  = root_data + \"dl3/\"\n",
    "dir_irfs = root_data + \"irfs/\"\n",
    "\n",
    "\n",
    "# Creating the directories in case they don't exist\n",
    "for path in [os.path.dirname(config_file), dir_dl1b, dir_dl2, dir_dl2m, dir_dl3, dir_irfs]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(os.path.join(path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8d10f",
   "metadata": {},
   "source": [
    "# Opening and storing configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = get_standard_config()\n",
    "# print(config_dict)\n",
    "\n",
    "#-------------------\n",
    "# Changes in the configuration should be done here\n",
    "\n",
    "# We select the heuristic flatfield option in the standard configuration\n",
    "config_dict[\"source_config\"][\"LSTEventSource\"][\"use_flatfield_heuristic\"] = True\n",
    "\n",
    "#-------------------\n",
    "\n",
    "with open(config_file, 'w') as json_file:\n",
    "    json.dump(config_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b32e12",
   "metadata": {},
   "source": [
    "# Finding the files that interest us\n",
    "#### Extracting dl1 files and dl1 datachecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95eb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting coordinates of source\n",
    "source_coords = SkyCoord.from_name(source_name)\n",
    "\n",
    "dict_source = {\n",
    "    \"name\"   : source_name,\n",
    "    \"coords\" : source_coords,\n",
    "    \"ra\"     : source_coords.ra.deg  * u.deg, # ra in degrees\n",
    "    \"dec\"    : source_coords.dec.deg * u.deg, # dec in degrees\n",
    "}\n",
    "\n",
    "# We create a empty dictionary to store all the information needed inside\n",
    "DICT = {}\n",
    "for run in run_numbers:\n",
    "    DICT[run] = {\n",
    "        \"run_num\" : run\n",
    "    }\n",
    "\n",
    "DICT = utils.add_dl1_paths_to_dict(DICT, dl1_root)\n",
    "DICT = utils.add_dl1_paths_to_dict(DICT, dl1_root, dchecking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac5fda0",
   "metadata": {},
   "source": [
    "#### Then we read the observations information and also the selected nodes for MC and RFs and we add it to the DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for run in run_numbers:\n",
    "\n",
    "    tab = read_table(DICT[run][\"dchecks\"][\"runwise\"], \"/dl1datacheck/cosmics\")\n",
    "    \n",
    "    # reading the variables\n",
    "    _zd,     _az       = 90 - np.rad2deg(np.array(tab[\"mean_alt_tel\"])), np.rad2deg(np.array(tab[\"mean_az_tel\"]))\n",
    "    _t_start, _t_elapsed = tab[\"dragon_time\"][0][0],                       np.array(tab[\"elapsed_time\"])\n",
    "    \n",
    "    DICT[run][\"time\"] = {\n",
    "        \"tstart\"   : _t_start,            # datetime object\n",
    "        \"telapsed\" : np.sum(_t_elapsed),  # s\n",
    "        \"srunwise\" : {\n",
    "            \"telapsed\" : _t_elapsed,      # s      \n",
    "        },\n",
    "    }\n",
    "    DICT[run][\"pointing\"] = {\n",
    "        \"zd\" : np.mean(_zd),  # deg\n",
    "        \"az\" : np.mean(_az),  # deg\n",
    "        \"srunwise\" : {\n",
    "            \"zd\" : _zd,       # deg\n",
    "            \"az\" : _az,       # deg\n",
    "        },\n",
    "    }\n",
    "    \n",
    "# then we also select the RFs and MC files looking at the nodes available\n",
    "DICT, dict_nodes = utils.add_mc_and_rfs_nodes(DICT, rfs_root, mcs_root, dict_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "fig.suptitle(\"MC nodes and observation pointings\")\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122, projection=\"polar\")\n",
    "\n",
    "colors = [np.random.rand(3) for _ in range(len(run_numbers))] # random color for each run\n",
    "for method, ax in zip([np.array, np.deg2rad], [ax1, ax2]):\n",
    "    for i, run in enumerate(run_numbers):\n",
    "        \n",
    "        ax.plot(method(DICT[run][\"pointing\"][\"srunwise\"][\"az\"]), DICT[run][\"pointing\"][\"srunwise\"][\"zd\"], marker=\"\",  color=colors[i], ls=\"-\", lw=2)\n",
    "        ax.plot(method(DICT[run][\"pointing\"][\"az\"]),             DICT[run][\"pointing\"][\"zd\"],             marker=\"o\", color=colors[i], ls=\"\",  ms=2)\n",
    " \n",
    "        ax.plot([], [], marker=\"o\", ls=\"-\", lw=2, color=colors[i], label=f\"Run {run}\")\n",
    "    ax.plot(method(dict_nodes[\"pointing\"][\"az\"]), dict_nodes[\"pointing\"][\"zd\"], marker=\"x\", ls=\"\", color=\"k\", zorder=-10, label=\"MC nodes\")\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.grid(True, zorder=-100)\n",
    "    ax.set_ylim(0, 90)\n",
    "ax1.set_xlim(0, 360)\n",
    "ax2.legend(loc=\"upper left\", bbox_to_anchor=(1, 1.1))\n",
    "ax2.set_yticks([22.5, 45, 67.5], [])\n",
    "ax1.set_xlabel(\"az [deg]\")\n",
    "ax1.set_ylabel(\"zd [deg]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7facb6",
   "metadata": {},
   "source": [
    "# DL1a to DL1b\n",
    "\n",
    "### <span style=\"color:red\">Bug: OSError: Unsupported version of subarray table: 1.0 (fixed adding the telescope geometry manually)</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for ir, run in enumerate(DICT.keys()):\n",
    "\n",
    "    dir_run = dir_dl1b + f\"{run:05}\" + \"/\"\n",
    "    sruns = [int(path.split(\".\")[-2]) for path in DICT[run][\"dl1a\"][\"srunwise\"]]\n",
    "    DICT[run][\"dl1b\"] = {\"srunwise\" : []}\n",
    "    \n",
    "    # Create a folder for each run\n",
    "    if not os.path.exists(dir_run):\n",
    "        os.makedirs(os.path.join(dir_run), exist_ok=True)\n",
    "\n",
    "    for i, srun in enumerate(sruns[:subruns_num]):\n",
    "\n",
    "        input_fname  = DICT[run][\"dl1a\"][\"srunwise\"][i]\n",
    "        output_fname = dir_run + f\"dl1_LST-1.Run{run:05}.{srun:04}.h5\"\n",
    "\n",
    "        print(f\"\\nComputing dl1b Run {run:5} Subrun {srun:04} - {i/len(sruns)*100:3.1f}% sruns {ir+1}/{len(DICT.keys())} runs\")\n",
    "        print(f\"--> {output_fname}\\n\")\n",
    "\n",
    "        !lstchain_dl1ab \\\n",
    "          --input-file $input_fname \\\n",
    "          --output-file $output_fname \\\n",
    "          --config $config_file \\\n",
    "          --no-image\n",
    "\n",
    "        DICT[run][\"dl1b\"][\"srunwise\"].append(output_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4483a6",
   "metadata": {},
   "source": [
    "# DL1b to DL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for ir, run in enumerate(DICT.keys()):\n",
    "\n",
    "    dir_run = dir_dl2 + f\"{run:05}\" + \"/\"\n",
    "    sruns = [int(path.split(\".\")[-2]) for path in DICT[run][\"dl1a\"][\"srunwise\"]]\n",
    "    DICT[run][\"dl2\"] = {\"srunwise\" : []}\n",
    "    \n",
    "    # Create a folder for each run\n",
    "    if not os.path.exists(dir_run):\n",
    "        os.makedirs(os.path.join(dir_run), exist_ok=True)\n",
    "    \n",
    "    for i, srun in enumerate(sruns[:subruns_num]):\n",
    "\n",
    "        input_fname  = DICT[run][\"dl1b\"][\"srunwise\"][i]\n",
    "        output_fname = dir_run + input_fname.split(\"/\")[-1].replace(\"dl1\", \"dl2\", 1)\n",
    "        rf_node      = DICT[run][\"simulations\"][\"rf\"]\n",
    "\n",
    "        # Check if the file exists and delete if exists (may be empty or half filled)\n",
    "        if os.path.exists(output_fname):\n",
    "            print(f\"File already exists, deleting and re-computing:\\n-->{output_fname}\")\n",
    "            os.remove(output_fname)\n",
    "\n",
    "        print(f\"\\nComputing dl1b Run {run:5} Subrun {srun:04} - {i/len(sruns)*100:3.1f}% sruns {ir+1}/{len(DICT.keys())} runs\")\n",
    "        print(f\"--> {output_fname}\\n\")\n",
    "\n",
    "        !lstchain_dl1_to_dl2 \\\n",
    "          --input-files $input_fname \\\n",
    "          --path-models $rf_node \\\n",
    "          --output-dir $dir_run \\\n",
    "          --config $config_file\n",
    "\n",
    "        DICT[run][\"dl2\"][\"srunwise\"].append(output_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c28194",
   "metadata": {},
   "source": [
    "# DL2 merging run-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549af078",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for ir, run in enumerate(DICT.keys()):\n",
    "\n",
    "    dir_run = dir_dl2 + f\"{run:05}\" + \"/\"\n",
    "    output_fname = dir_dl2m + f\"dl2_LST-1.Run{run:05}.h5\"\n",
    "    \n",
    "    !lstchain_merge_hdf5_files \\\n",
    "      --input-dir $dir_run \\\n",
    "      --output-file $output_fname \\\n",
    "      --run-number $run \\\n",
    "      --no-image\n",
    "    \n",
    "    DICT[run][\"dl2\"][\"runwise\"] = output_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b96c170",
   "metadata": {},
   "source": [
    "# MCs to IRFs\n",
    "### <span style=\"color:red\">Version of pyirf needed, at least v0.10</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Already computed IRFs\n",
    "computed_irfs = glob.glob(dir_irfs + \"*\")\n",
    "\n",
    "for ir, run in enumerate(DICT.keys()):\n",
    "    \n",
    "    input_mc = DICT[run][\"simulations\"][\"mc\"]\n",
    "\n",
    "    output_irf = dir_irfs + \"irf_{}_{}.fits.gz\".format(input_mc.split(\"/\")[-3], input_mc.split(\"/\")[-2])\n",
    "\n",
    "    # we don't compute the IRF if it has been already done\n",
    "    if output_irf not in computed_irfs:\n",
    "        \n",
    "        print(f\"\\nComputing IRF for Run {run:5}, {ir+1}/{len(DICT.keys())} runs\")\n",
    "        print(f\"--> {output_irf}\\n\")\n",
    "        \n",
    "        !lstchain_create_irf_files \\\n",
    "          --input-gamma-dl2 $input_mc \\\n",
    "          --output-irf-file $output_irf \\\n",
    "          --point-like \\\n",
    "          --energy-dependent-gh \\\n",
    "          --energy-dependent-theta \\\n",
    "          --overwrite\n",
    "    else:\n",
    "        print(\"\\nIRF {}_{} already computed\\n\".format(input_mc.split(\"/\")[-3], input_mc.split(\"/\")[-2]))\n",
    "    DICT[run][\"irf\"] = output_irf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427be0b9",
   "metadata": {},
   "source": [
    "# DL2 to DL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bef92ad-fc26-4790-9d1e-9aa6fa778df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ra_str  = \"{}\".format(dict_source[\"ra\"]).replace(\" \", \"\")\n",
    "dec_str = \"{}\".format(dict_source[\"dec\"]).replace(\" \", \"\")\n",
    "\n",
    "for ir, run in enumerate(DICT.keys()):\n",
    "\n",
    "    # dir_run = dir_dl3 + f\"{run:05}\" + \"/\"    \n",
    "    dl2_fname = DICT[run][\"dl2\"][\"runwise\"]\n",
    "\n",
    "    output_dl3 = dir_dl3 + f\"dl3_LST-1.Run{run:05}.fits\"\n",
    "    \n",
    "    print(f\"\\nConverting dl2 for {run:5}, {ir+1}/{len(DICT.keys())} runs\")\n",
    "    print(f\"--> {output_dl3}\\n\")\n",
    "    \n",
    "    !lstchain_create_dl3_file \\\n",
    "      --input-dl2 $dl2_fname \\\n",
    "      --input-irf-path $dir_irfs \\\n",
    "      --output-dl3-path $dir_dl3 \\\n",
    "      --source-name $source_name \\\n",
    "      --source-ra $ra_str \\\n",
    "      --source-dec $dec_str \\\n",
    "      --config $config_file \\\n",
    "      --overwrite\n",
    "\n",
    "    DICT[run][\"dl3\"] = output_dl3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be4be3",
   "metadata": {},
   "source": [
    "## Add DL3 index files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"All dl3 files created 100%\\n\\n\\nCreating index files...\")\n",
    "\n",
    "# Creating the index file\n",
    "!lstchain_create_dl3_index_files \\\n",
    "--input-dl3-dir $dir_dl3 \\\n",
    "--file-pattern 'dl3*.fits' \\\n",
    "--overwrite\n",
    "\n",
    "print(f\"\\nFinished with the dl3 process\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
