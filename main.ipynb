{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b4638",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from datetime import datetime\n",
    "import pickle, json, sys, os, glob\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "\n",
    "import utils\n",
    "\n",
    "from traitlets.config.loader import Config\n",
    "from astropy.coordinates     import SkyCoord\n",
    "from lstchain.io.config      import get_standard_config\n",
    "from ctapipe.io              import read_table\n",
    "\n",
    "# compute_dl1b"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cff6f04",
   "metadata": {},
   "source": [
    "# Some configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56ff173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source specifications\n",
    "source_name = \"crab\"\n",
    "\n",
    "# Maybe we add a way to extract the run numbers we are interested in\n",
    "run_numbers = [15272] # [6172, 6242, 6194, 6193, 15337, 15272, 15339, 15340] # [15272] # [15337, 15272]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ea7368",
   "metadata": {},
   "source": [
    "# Paths to data and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66854bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Root path of this script\n",
    "root = \"/fefs/aswg/workspace/juan.jimenez/lst_pipeline/\"\n",
    "# Path to store the configuration file we are going to use\n",
    "config_file = root + \"objects/standard_config.json\"\n",
    "# Data main directory\n",
    "root_data = root + f\"../data/tests/{source_name}/\"\n",
    "\n",
    "# STANDARD paths ---------\n",
    "# DL1 data root\n",
    "dl1_root = \"/fefs/aswg/data/real/DL1/*/v0.*/tailcut84/\"\n",
    "# RFs root main directory\n",
    "rfs_root = \"/fefs/aswg/data/models/AllSky/20230901_v0.10.4_allsky_base_prod/\"\n",
    "# MCs dl2 main directory\n",
    "mcs_root = \"/fefs/aswg/data/mc/DL2/AllSky/20230901_v0.10.4_allsky_base_prod/TestingDataset/\"\n",
    "\n",
    "\n",
    "# directories for the data\n",
    "dir_dl1b = root_data + \"dl1b/\"\n",
    "dir_dl2  = root_data + \"dl2/\"\n",
    "dir_dl3  = root_data + \"dl3/\"\n",
    "dir_irfs = root_data + \"irfs/\"\n",
    "\n",
    "\n",
    "# Creating the directories in case they don't exist\n",
    "for path in [os.path.dirname(config_file), dir_dl1b, dir_dl2, dir_dl3, dir_irfs]:\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(os.path.join(path), exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb8d10f",
   "metadata": {},
   "source": [
    "# Opening and storing configuration file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5030e785",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_dict = get_standard_config()\n",
    "# print(config_dict)\n",
    "\n",
    "#-------------------\n",
    "# Changes in the configuration should be done here\n",
    "\n",
    "# We select the heuristic flatfield option in the standard configuration\n",
    "config_dict[\"source_config\"][\"LSTEventSource\"][\"use_flatfield_heuristic\"] = True\n",
    "\n",
    "#-------------------\n",
    "\n",
    "with open(config_file, 'w') as json_file:\n",
    "    json.dump(config_dict, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b32e12",
   "metadata": {},
   "source": [
    "# Finding the files that interest us\n",
    "#### Extracting dl1 files and dl1 datachecks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95eb908",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting coordinates of source\n",
    "source_coords = SkyCoord.from_name(source_name)\n",
    "\n",
    "dict_source = {\n",
    "    \"name\"   : source_name,\n",
    "    \"coords\" : source_coords,\n",
    "    \"ra\"     : source_coords.ra.deg  * u.deg, # ra in degrees\n",
    "    \"dec\"    : source_coords.dec.deg * u.deg, # dec in degrees\n",
    "}\n",
    "\n",
    "# We create a empty dictionary to store all the information needed inside\n",
    "DICT = {}\n",
    "for run in run_numbers:\n",
    "    DICT[run] = {\n",
    "        \"run_num\" : run,\n",
    "        \"errors\"  : \"\", # log of errors trough the analysis\n",
    "    }\n",
    "\n",
    "DICT = utils.add_dl1_paths_to_dict(DICT, dl1_root)\n",
    "DICT = utils.add_dl1_paths_to_dict(DICT, dl1_root, dchecking=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fac5fda0",
   "metadata": {},
   "source": [
    "#### Then we read the observations information and also the selected nodes for MC and RFs and we add it to the DICT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f1e1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for run in run_numbers:\n",
    "\n",
    "    tab = read_table(DICT[run][\"dchecks\"][\"runwise\"], \"/dl1datacheck/cosmics\")\n",
    "    \n",
    "    # reading the variables\n",
    "    _zd,     _az       = 90 - np.rad2deg(np.array(tab[\"mean_alt_tel\"])), np.rad2deg(np.array(tab[\"mean_az_tel\"]))\n",
    "    _t_start, _t_elapsed = tab[\"dragon_time\"][0][0],                       np.array(tab[\"elapsed_time\"])\n",
    "    \n",
    "    DICT[run][\"time\"] = {\n",
    "        \"tstart\"   : _t_start,            # datetime object\n",
    "        \"telapsed\" : np.sum(_t_elapsed),  # s\n",
    "        \"srunwise\" : {\n",
    "            \"telapsed\" : _t_elapsed,      # s      \n",
    "        },\n",
    "    }\n",
    "    DICT[run][\"pointing\"] = {\n",
    "        \"zd\" : np.mean(_zd),  # deg\n",
    "        \"az\" : np.mean(_az),  # deg\n",
    "        \"srunwise\" : {\n",
    "            \"zd\" : _zd,       # deg\n",
    "            \"az\" : _az,       # deg\n",
    "        },\n",
    "    }\n",
    "    \n",
    "# then we also select the RFs and MC files looking at the nodes available\n",
    "DICT, dict_nodes = utils.add_mc_and_rfs_nodes(DICT, rfs_root, mcs_root, dict_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6831dd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 5))\n",
    "fig.suptitle(\"MC nodes and observation pointings\")\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122, projection=\"polar\")\n",
    "\n",
    "colors = [np.random.rand(3) for _ in range(len(run_numbers))] # random color for each run\n",
    "for method, ax in zip([np.array, np.deg2rad], [ax1, ax2]):\n",
    "    for i, run in enumerate(run_numbers):\n",
    "        \n",
    "        ax.plot(method(DICT[run][\"pointing\"][\"srunwise\"][\"az\"]), DICT[run][\"pointing\"][\"srunwise\"][\"zd\"], marker=\"\",  color=colors[i], ls=\"-\", lw=2)\n",
    "        ax.plot(method(DICT[run][\"pointing\"][\"az\"]),             DICT[run][\"pointing\"][\"zd\"],             marker=\"o\", color=colors[i], ls=\"\",  ms=2)\n",
    " \n",
    "        ax.plot([], [], marker=\"o\", ls=\"-\", lw=2, color=colors[i], label=f\"Run {run}\")\n",
    "    ax.plot(method(dict_nodes[\"pointing\"][\"az\"]), dict_nodes[\"pointing\"][\"zd\"], marker=\"x\", ls=\"\", color=\"k\", zorder=-10, label=\"MC nodes\")\n",
    "\n",
    "for ax in [ax1, ax2]:\n",
    "    ax.grid(True, zorder=-100)\n",
    "    ax.set_ylim(0, 90)\n",
    "ax1.set_xlim(0, 360)\n",
    "ax2.legend(loc=\"upper left\", bbox_to_anchor=(1, 1.1))\n",
    "ax2.set_yticks([22.5, 45, 67.5], [])\n",
    "ax1.set_xlabel(\"az [deg]\")\n",
    "ax1.set_ylabel(\"zd [deg]\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7facb6",
   "metadata": {},
   "source": [
    "# DL1a to DL1b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88c2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for ir, run in enumerate(DICT.keys()):\n",
    "\n",
    "    sruns = [int(path.split(\".\")[-2]) for path in DICT[run][\"dl1a\"][\"srunwise\"]]\n",
    "    DICT[run][\"dl1b\"] = {\"srunwise\" : []}\n",
    "\n",
    "    for i, srun in enumerate(sruns):\n",
    "\n",
    "        input_fname  = DICT[run][\"dl1a\"][\"srunwise\"][i]\n",
    "        output_fname = dir_dl1b + f\"dl1_LST-1.Run{run:05}.{srun:04}.h5\"\n",
    "\n",
    "        print(f\"\\nComputing dl1b Run {run:5} Subrun {srun:04} - {i/len(sruns)*100:3.1f}% sruns {ir+1}/{len(DICT.keys())} runs\")\n",
    "        print(f\"--> {output_fname}\\n\")\n",
    "\n",
    "#         !lstchain_dl1ab \\\n",
    "#           -f $input_fname \\\n",
    "#           -o $output_fname \\\n",
    "#           -c $config_file \\\n",
    "#           --no-image \\\n",
    "\n",
    "        DICT[run][\"dl1b\"][\"srunwise\"].append(output_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4483a6",
   "metadata": {},
   "source": [
    "# DL1b to DL2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe4dd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for ir, run in enumerate(DICT.keys()):\n",
    "            \n",
    "    sruns = [int(path.split(\".\")[-2]) for path in DICT[run][\"dl1a\"][\"srunwise\"]]\n",
    "    DICT[run][\"dl2\"] = {\"srunwise\" : []}\n",
    "\n",
    "    for i, srun in enumerate(sruns):\n",
    "\n",
    "        input_fname  = DICT[run][\"dl1b\"][\"srunwise\"][i]\n",
    "        output_fname = dir_dl2 + input_fname.split(\"/\")[-1].replace(\"dl1\", \"dl2\", 1)\n",
    "        rf_node      = DICT[run][\"simulations\"][\"rf\"]\n",
    "\n",
    "        print(f\"\\nComputing dl1b Run {run:5} Subrun {srun:04} - {i/len(sruns)*100:3.1f}% sruns {ir+1}/{len(DICT.keys())} runs\")\n",
    "        print(f\"--> {output_fname}\\n\")\n",
    "\n",
    "#         !lstchain_dl1_to_dl2 \\\n",
    "#           -f $input_fname \\\n",
    "#           -p $rf_node \\\n",
    "#           -o $dir_dl2 \\\n",
    "#           -c $config_file \\\n",
    "\n",
    "        DICT[run][\"dl2\"][\"srunwise\"].append(output_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c28194",
   "metadata": {},
   "source": [
    "# DL2 merging run-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549af078",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for ir, run in enumerate(DICT.keys()):\n",
    "    \n",
    "    output_fname = dir_dl2 + f\"dl2_LST-1.Run{run:05}.h5\"\n",
    "    \n",
    "#     !lstchain_merge_hdf5_files \\\n",
    "#       -d $dir_dl2 \\\n",
    "#       -o $output_fname \\\n",
    "#       --run-number $run \\\n",
    "#       --no-image \\\n",
    "    \n",
    "    DICT[run][\"dl2\"][\"runwise\"] = output_fname"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b96c170",
   "metadata": {},
   "source": [
    "# MCs to IRFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d8ad8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Already computed IRFs\n",
    "computed_irfs = glob.glob(dir_irfs + \"*\")\n",
    "\n",
    "for ir, run in enumerate(DICT.keys()):\n",
    "    \n",
    "    output_fname = dir_dl2 + f\"dl2_LST-1.Run{run:05}.h5\"\n",
    "    input_mc = DICT[run][\"simulations\"][\"mc\"]\n",
    "\n",
    "    output_irf = dir_irfs + \"irf_{}_{}.fits.gz\".format(input_mc.split(\"/\")[-3], input_mc.split(\"/\")[-2])\n",
    "\n",
    "    # we don't compute the IRF if it has been already done\n",
    "    if output_irf not in computed_irfs:\n",
    "        \n",
    "        print(f\"\\nComputing IRF for Run {run:5}, {ir+1}/{len(DICT.keys())} runs\")\n",
    "        print(f\"--> {output_irf}\\n\")\n",
    "        \n",
    "        !lstchain_create_irf_files \\\n",
    "          --input-gamma-dl2 $input_mc \\\n",
    "          --output-irf-file $output_irf \\\n",
    "          --point-like \\\n",
    "          --energy-dependent-gh \\\n",
    "          --energy-dependent-theta \\\n",
    "          --overwrite \\   \n",
    "    else:\n",
    "        print(\"\\nIRF {}_{} already computed\\n\".format(input_mc.split(\"/\")[-3], input_mc.split(\"/\")[-2]))\n",
    "\n",
    "    DICT[run][\"irf\"] = output_irf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427be0b9",
   "metadata": {},
   "source": [
    "# DL2 to DL3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d4de30-7c54-4777-991d-2309e159a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_mc = '/fefs/aswg/data/mc/DL2/AllSky/20221027_v0.9.9_crab_tuned/TestingDataset/dec_2276/node_theta_32.059_az_248.099_/dl2_20221027_v0.9.9_crab_tuned_node_theta_32.059_az_248.099__merged.h5'\n",
    "output_irf = \"irf_mc_theta_10.0_az_102.199.fits.gz\"\n",
    "\n",
    "!lstchain_create_irf_files \\\n",
    "  --input-gamma-dl2 $input_mc \\\n",
    "  --output-irf-file $output_irf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c935387-b98b-4d09-830b-c120becd0169",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl2_fname = '/fefs/aswg/workspace/abelardo.moralejo/Crab_performance_paper/data_v0.9.9/DL2/process_with_mc_theta_10.0_az_102.199/dl2_LST-1.Run03319.h5'\n",
    "irf_fname = '/fefs/aswg/workspace/juan.jimenez/data/cosmic_ray_data_correction/performance_paper_data/irfs/irf_mc_theta_10.0_az_102.199.fits.gz'\n",
    "ra_str  = \"{}\".format(dict_source[\"ra\"]).replace(\" \", \"\")\n",
    "dec_str = \"{}\".format(dict_source[\"dec\"]).replace(\" \", \"\")\n",
    "\n",
    "!lstchain_create_dl3_file \\\n",
    "  --d $dl2_fname \\\n",
    "  --i $irf_fname \\\n",
    "  --o $dir_dl3 \\\n",
    "  --source-name $source_name \\\n",
    "  --source-ra  $ra_str \\\n",
    "  --source-dec $dec_str \\\n",
    "  --config $config_file \\\n",
    "  --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c53d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# ra_str  = \"{}deg\".format(dict_source[\"ra\"])\n",
    "# dec_str = \"{}deg\".format(dict_source[\"dec\"])\n",
    "# for ir, run in enumerate(DICT.keys()):\n",
    "\n",
    "#     dl2_fname = DICT[run][\"dl2\"][\"runwise\"]\n",
    "#     irf_fname = DICT[run][\"irf\"]\n",
    "    \n",
    "#     !lstchain_create_dl3_file \\\n",
    "#       --d $dl2_fname \\\n",
    "#       --i $irf_fname \\\n",
    "#       --o $dir_dl3 \\\n",
    "#       --source-name $source_name \\\n",
    "#       --source-ra  $ra_str \\\n",
    "#       --source-dec $dec_str \\\n",
    "#       --config $config_file \\\n",
    "#       --overwrite \\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1be4be3",
   "metadata": {},
   "source": [
    "## Add DL3 index files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2719e761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logger.info(f\"All dl3 files created 100%\\n\\n\\nCreating index files...\")\n",
    "\n",
    "# # Creating the index file\n",
    "# !lstchain_create_dl3_index_files \\\n",
    "# --input-dl3-dir $path_dl3 \\\n",
    "# --file-pattern 'dl3*.fits' \\\n",
    "# --overwrite\n",
    "\n",
    "# logger.info(f\"Finished with the dl3 process\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
